{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df3eda8e",
      "metadata": {
        "id": "df3eda8e"
      },
      "source": [
        "# Решение задачи предсказания дефолта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "SdTMLOOiTSV5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdTMLOOiTSV5",
        "outputId": "a5009a47-f9c0-41c7-ba10-eddd4556af43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading school-of-quants-hackathon-2025-finals.zip to /content\n",
            "\r  0% 0.00/43.2M [00:00<?, ?B/s]\n",
            "\r100% 43.2M/43.2M [00:00<00:00, 1.08GB/s]\n",
            "Archive:  school-of-quants-hackathon-2025-finals.zip\n",
            "  inflating: X_test.csv              \n",
            "  inflating: X_train.csv             \n",
            "  inflating: y_train.csv             \n"
          ]
        }
      ],
      "source": [
        "# Загрузка данных с kaggle. Нужно загрузить kaggle.json с профиля в Kaggle.\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c school-of-quants-hackathon-2025-finals\n",
        "!unzip school-of-quants-hackathon-2025-finals.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "P_2edmflU-8i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_2edmflU-8i",
        "outputId": "11c2b882-e626-408c-cd03-834413383db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Shapes: (1827404, 48) (456852, 48) (1827404, 2)\n",
            "Target distribution:\n",
            " flag\n",
            "0    0.967186\n",
            "1    0.032814\n",
            "Name: proportion, dtype: float64\n",
            "Preparing features...\n",
            "Prepared feature shapes: (1827404, 41) (456852, 41)\n",
            "Training with balance_method = undersample\n",
            "Fold 1\n",
            "  Undersampled train: pos=47971, neg=191884\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's auc: 0.641359\n",
            "[200]\tvalid_0's auc: 0.644107\n",
            "[300]\tvalid_0's auc: 0.64506\n",
            "[400]\tvalid_0's auc: 0.645076\n",
            "Early stopping, best iteration is:\n",
            "[341]\tvalid_0's auc: 0.645407\n",
            "  Fold ROC AUC: 0.64541, best F1=0.11698 at thr=0.326\n",
            "Fold 2\n",
            "  Undersampled train: pos=47971, neg=191884\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's auc: 0.635652\n",
            "[200]\tvalid_0's auc: 0.638765\n",
            "[300]\tvalid_0's auc: 0.639222\n",
            "Early stopping, best iteration is:\n",
            "[296]\tvalid_0's auc: 0.639387\n",
            "  Fold ROC AUC: 0.63939, best F1=0.11297 at thr=0.307\n",
            "Fold 3\n",
            "  Undersampled train: pos=47971, neg=191884\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's auc: 0.642063\n",
            "[200]\tvalid_0's auc: 0.645405\n",
            "[300]\tvalid_0's auc: 0.645983\n",
            "Early stopping, best iteration is:\n",
            "[282]\tvalid_0's auc: 0.646112\n",
            "  Fold ROC AUC: 0.64611, best F1=0.11988 at thr=0.326\n",
            "Fold 4\n",
            "  Undersampled train: pos=47971, neg=191884\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's auc: 0.641488\n",
            "[200]\tvalid_0's auc: 0.645868\n",
            "[300]\tvalid_0's auc: 0.64632\n",
            "[400]\tvalid_0's auc: 0.646733\n",
            "[500]\tvalid_0's auc: 0.646418\n",
            "Early stopping, best iteration is:\n",
            "[415]\tvalid_0's auc: 0.646844\n",
            "  Fold ROC AUC: 0.64684, best F1=0.12163 at thr=0.326\n",
            "Fold 5\n",
            "  Undersampled train: pos=47972, neg=191888\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's auc: 0.641273\n",
            "[200]\tvalid_0's auc: 0.64531\n",
            "[300]\tvalid_0's auc: 0.646141\n",
            "[400]\tvalid_0's auc: 0.646345\n",
            "Early stopping, best iteration is:\n",
            "[360]\tvalid_0's auc: 0.646546\n",
            "  Fold ROC AUC: 0.64655, best F1=0.11755 at thr=0.344\n",
            "Best threshold on OOF: 0.3255102040816326 Best OOF F1: 0.11755140466867792\n",
            "Predicting test set...\n",
            "Saved submission.csv, shape: (456852, 2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import f1_score, precision_recall_curve, roc_auc_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "DATA_DIR = \".\"\n",
        "\n",
        "# ---------------- Data ----------------\n",
        "\n",
        "def load_data(data_dir=DATA_DIR):\n",
        "    X_train = pd.read_csv(os.path.join(data_dir, \"X_train.csv\"))\n",
        "    X_test = pd.read_csv(os.path.join(data_dir, \"X_test.csv\"))\n",
        "    y_train = pd.read_csv(os.path.join(data_dir, \"y_train.csv\"))\n",
        "    return X_train, X_test, y_train\n",
        "\n",
        "def basic_checks(X_train, X_test, y_train):\n",
        "    print(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape)\n",
        "    if y_train.shape[1] > 1:\n",
        "        if 'flag' in y_train.columns:\n",
        "            y = y_train['flag'].astype(int)\n",
        "        else:\n",
        "            y = y_train.iloc[:, 0].astype(int)\n",
        "    else:\n",
        "        y = y_train.iloc[:, 0].astype(int)\n",
        "    vc = y.value_counts(normalize=True)\n",
        "    print(\"Target distribution:\\n\", vc.rename(\"proportion\"))\n",
        "    return y\n",
        "\n",
        "# ---------------- Feature engineering ----------------\n",
        "\n",
        "def eng_enc_paym_features(df, enc_cols):\n",
        "    if len(enc_cols) == 0:\n",
        "        return pd.DataFrame(index=df.index)\n",
        "    arr = df[enc_cols].fillna(-99).values\n",
        "    valid_mask = (arr != -99)\n",
        "\n",
        "    def first_val(a, vm):\n",
        "        out = np.full(a.shape[0], np.nan, dtype=float)\n",
        "        idx = vm.argmax(axis=1)\n",
        "        any_valid = vm.any(axis=1)\n",
        "        out[any_valid] = a[np.arange(a.shape[0])[any_valid], idx[any_valid]]\n",
        "        return out\n",
        "\n",
        "    def last_val(a, vm):\n",
        "        out = np.full(a.shape[0], np.nan, dtype=float)\n",
        "        rev_idx = vm[:, ::-1].argmax(axis=1)\n",
        "        any_valid = vm.any(axis=1)\n",
        "        rev_pos = a.shape[1] - 1 - rev_idx\n",
        "        out[any_valid] = a[np.arange(a.shape[0])[any_valid], rev_pos[any_valid]]\n",
        "        return out\n",
        "\n",
        "    first_v = first_val(arr, valid_mask)\n",
        "    last_v = last_val(arr, valid_mask)\n",
        "    mean_v = np.nanmean(np.where(valid_mask, arr, np.nan), axis=1)\n",
        "    std_v = np.nanstd(np.where(valid_mask, arr, np.nan), axis=1)\n",
        "    n_unique = np.apply_along_axis(lambda r: len(np.unique(r[r != -99])), 1, arr)\n",
        "    missing_frac = (arr == -99).mean(axis=1)\n",
        "    diffs = np.diff(np.where(arr == -99, np.nan, arr), axis=1)\n",
        "    slope = np.nanmean(diffs, axis=1)\n",
        "    num_changes = np.nansum((~np.isnan(diffs)) & (diffs != 0), axis=1)\n",
        "\n",
        "    out = pd.DataFrame({\n",
        "        \"enc_first\": first_v,\n",
        "        \"enc_last\": last_v,\n",
        "        \"enc_mean\": mean_v,\n",
        "        \"enc_std\": std_v,\n",
        "        \"enc_n_unique\": n_unique,\n",
        "        \"enc_missing_frac\": missing_frac,\n",
        "        \"enc_num_changes\": num_changes,\n",
        "        \"enc_trend\": slope\n",
        "    }, index=df.index)\n",
        "    return out\n",
        "\n",
        "def eng_overdues_features(df, over_cols, no_over_cols):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    if len(over_cols) > 0:\n",
        "        arr = df[over_cols].fillna(0).values.astype(float)\n",
        "        out['over_total'] = arr.sum(axis=1)\n",
        "        out['over_num_nonzero'] = (arr > 0).sum(axis=1)\n",
        "        out['over_max_bucket'] = np.argmax(arr, axis=1).astype(int)\n",
        "        out['over_std'] = arr.std(axis=1)\n",
        "    else:\n",
        "        out[['over_total','over_num_nonzero','over_max_bucket','over_std']] = 0\n",
        "    if len(no_over_cols) > 0:\n",
        "        arr2 = df[no_over_cols].fillna(0).values.astype(float)\n",
        "        out['no_over_total'] = arr2.sum(axis=1)\n",
        "        out['no_over_mean'] = arr2.mean(axis=1)\n",
        "        out['no_over_std'] = arr2.std(axis=1)\n",
        "    else:\n",
        "        out[['no_over_total','no_over_mean','no_over_std']] = 0\n",
        "    return out\n",
        "\n",
        "def num_features_engineer(df):\n",
        "    df = df.copy()\n",
        "    EPS = 1e-9\n",
        "    if 'maturity_plan' in df.columns and 'maturity_fact' in df.columns:\n",
        "        df['maturity_diff'] = df['maturity_fact'] - df['maturity_plan']\n",
        "        df['maturity_ratio'] = df['maturity_fact'] / (df['maturity_plan'] + EPS)\n",
        "        df['closed_early'] = (df['maturity_fact'] < df['maturity_plan']).astype(int)\n",
        "    if 'sum_left_to_pay' in df.columns and 'credit_limit' in df.columns:\n",
        "        df['utilization'] = df['sum_left_to_pay'] / (df['credit_limit'] + EPS)\n",
        "    if 'next_payment_sum' in df.columns and 'credit_limit' in df.columns:\n",
        "        df['next_payment_ratio'] = df['next_payment_sum'] / (df['credit_limit'] + EPS)\n",
        "    if 'current_overdue_debt' in df.columns:\n",
        "        df['has_current_overdue'] = (df['current_overdue_debt'] > 0).astype(int)\n",
        "    money_cols = ['credit_limit','next_payment_sum','sum_left_to_pay','current_overdue_debt','max_overdue_debt','full_credit_cost']\n",
        "    for c in money_cols:\n",
        "        if c in df.columns:\n",
        "            df[c + '_log1p'] = np.log1p(df[c].fillna(0.0).astype(float))\n",
        "    if 'maturity_plan' in df.columns and 'days_since_confirmed' in df.columns:\n",
        "        df['maturity_remaining'] = df['maturity_plan'] - df['days_since_confirmed']\n",
        "    return df\n",
        "\n",
        "def prepare_features(X_train, X_test):\n",
        "    all_cols = X_train.columns.tolist()\n",
        "    enc_paym_cols = [c for c in all_cols if c.startswith('enc_paym_')]\n",
        "    over_cols = [c for c in all_cols if c.startswith('overdues_')]\n",
        "    no_over_cols = [c for c in all_cols if c.startswith('no_overdues_')]\n",
        "    cat_cols = [c for c in ['credit_type','credit_currency'] if c in all_cols]\n",
        "    id_col = 'id' if 'id' in all_cols else None\n",
        "\n",
        "    X_train_num = num_features_engineer(X_train)\n",
        "    X_test_num  = num_features_engineer(X_test)\n",
        "\n",
        "    enc_tr = eng_enc_paym_features(X_train_num, enc_paym_cols)\n",
        "    enc_te = eng_enc_paym_features(X_test_num, enc_paym_cols)\n",
        "    ov_tr = eng_overdues_features(X_train_num, over_cols, no_over_cols)\n",
        "    ov_te = eng_overdues_features(X_test_num, over_cols, no_over_cols)\n",
        "\n",
        "    drop_cols = enc_paym_cols + over_cols + no_over_cols\n",
        "    X_train_small = pd.concat([X_train_num.drop(columns=[c for c in drop_cols if c in X_train_num.columns]), enc_tr, ov_tr], axis=1)\n",
        "    X_test_small  = pd.concat([X_test_num.drop(columns=[c for c in drop_cols if c in X_test_num.columns]), enc_te, ov_te], axis=1)\n",
        "\n",
        "    for c in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        X_train_small[c] = X_train_small[c].fillna(-999)\n",
        "        X_test_small[c]  = X_test_small[c].fillna(-999)\n",
        "        le.fit(list(X_train_small[c].astype(str).values) + list(X_test_small[c].astype(str).values))\n",
        "        X_train_small[c] = le.transform(X_train_small[c].astype(str))\n",
        "        X_test_small[c]  = le.transform(X_test_small[c].astype(str))\n",
        "\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train_small[:] = imputer.fit_transform(X_train_small)\n",
        "    X_test_small[:]  = imputer.transform(X_test_small)\n",
        "\n",
        "    for c in X_train_small.select_dtypes(include=[np.number]).columns:\n",
        "        if c in cat_cols:\n",
        "            X_train_small[c] = X_train_small[c].astype('int32')\n",
        "            X_test_small[c] = X_test_small[c].astype('int32')\n",
        "        else:\n",
        "            X_train_small[c] = X_train_small[c].astype('float32')\n",
        "            X_test_small[c] = X_test_small[c].astype('float32')\n",
        "\n",
        "    return X_train_small, X_test_small, id_col, cat_cols\n",
        "\n",
        "# ---------------- Training ----------------\n",
        "\n",
        "def undersample_negatives_idx(y, desired_neg_ratio=4, random_state=None):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    idx_all = y.index.values\n",
        "    pos_mask = (y.values == 1)\n",
        "    neg_mask = ~pos_mask\n",
        "    pos_idx = idx_all[pos_mask]\n",
        "    neg_idx = idx_all[neg_mask]\n",
        "    n_pos = pos_idx.shape[0]\n",
        "    n_neg_req = min(int(n_pos * desired_neg_ratio), neg_idx.shape[0])\n",
        "    if n_neg_req <= 0:\n",
        "        return idx_all\n",
        "    sampled_neg = rng.choice(neg_idx, size=n_neg_req, replace=False)\n",
        "    selected = np.concatenate([pos_idx, sampled_neg])\n",
        "    rng.shuffle(selected)\n",
        "    return selected\n",
        "\n",
        "def train_lgb_oof(X, y, cat_cols, n_splits=5, seed=42,\n",
        "                  balance_method='undersample', desired_neg_ratio=4):\n",
        "    base_params = {\n",
        "        'objective': 'binary',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'metric': 'auc',\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 127,\n",
        "        'n_estimators': 4000,\n",
        "        'min_data_in_leaf': 50,\n",
        "        'feature_fraction': 0.8,\n",
        "        'bagging_fraction': 0.8,\n",
        "        'bagging_freq': 1,\n",
        "        'lambda_l1': 1.0,\n",
        "        'lambda_l2': 1.0,\n",
        "        'random_state': seed,\n",
        "        'n_jobs': -1,\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    oof_preds = np.zeros(X.shape[0], dtype=float)\n",
        "    models = []\n",
        "\n",
        "    from lightgbm import early_stopping, log_evaluation\n",
        "\n",
        "    for fold, (tr_idx, val_idx) in enumerate(folds.split(X, y)):\n",
        "        print(\"Fold\", fold + 1)\n",
        "        X_tr_full, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr_full, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "\n",
        "        if balance_method in ('undersample', 'both'):\n",
        "            sel_idx = undersample_negatives_idx(y_tr_full, desired_neg_ratio=desired_neg_ratio, random_state=seed + fold)\n",
        "            X_tr = X_tr_full.loc[sel_idx]\n",
        "            y_tr = y_tr_full.loc[sel_idx]\n",
        "            print(f\"  Undersampled train: pos={int((y_tr==1).sum())}, neg={int((y_tr==0).sum())}\")\n",
        "        else:\n",
        "            X_tr, y_tr = X_tr_full, y_tr_full\n",
        "            print(f\"  Full train used: pos={int((y_tr==1).sum())}, neg={int((y_tr==0).sum())}\")\n",
        "\n",
        "        params = base_params.copy()\n",
        "        if balance_method in ('scale', 'both'):\n",
        "            pos = int(y_tr.sum())\n",
        "            neg = int(y_tr.shape[0] - pos)\n",
        "            spw = max(1.0, neg / (pos + 1e-9))\n",
        "            params['scale_pos_weight'] = spw\n",
        "            print(f\"  Using scale_pos_weight = {spw:.3f}\")\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
        "        lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train, categorical_feature=cat_cols, free_raw_data=False)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_val],\n",
        "            num_boost_round=params.get('n_estimators', 2000),\n",
        "            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=100)]\n",
        "        )\n",
        "\n",
        "        val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        oof_preds[val_idx] = val_pred\n",
        "        models.append(model)\n",
        "\n",
        "        auc = roc_auc_score(y_val, val_pred)\n",
        "        thr, f1 = find_best_threshold(y_val, val_pred)\n",
        "        print(f\"  Fold ROC AUC: {auc:.5f}, best F1={f1:.5f} at thr={thr:.3f}\")\n",
        "        gc.collect()\n",
        "\n",
        "    return models, oof_preds\n",
        "\n",
        "# ---------------- Utils ----------------\n",
        "\n",
        "def find_best_threshold(y_true, probs):\n",
        "    thresholds = np.linspace(0.05, 0.95, 50)\n",
        "    best_thr, best_f1 = 0.5, 0\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thr = t\n",
        "    return best_thr, best_f1\n",
        "\n",
        "def predict_ensemble(models, X, average=True):\n",
        "    preds = np.column_stack([m.predict(X, num_iteration=m.best_iteration) for m in models])\n",
        "    return preds.mean(axis=1)\n",
        "\n",
        "# ---------------- Main ----------------\n",
        "\n",
        "def main():\n",
        "    required = [\"X_train.csv\", \"X_test.csv\", \"y_train.csv\"]\n",
        "    ok = all(os.path.exists(f) for f in required)\n",
        "    if not ok:\n",
        "        print(\"Не найден один из файлов:\", required)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    X_train, X_test, y_df = load_data(DATA_DIR)\n",
        "    y = basic_checks(X_train, X_test, y_df)\n",
        "\n",
        "    print(\"Preparing features...\")\n",
        "    X_tr, X_te, id_col, cat_cols = prepare_features(X_train, X_test)\n",
        "    X_tr = X_tr.loc[y.index]\n",
        "    print(\"Prepared feature shapes:\", X_tr.shape, X_te.shape)\n",
        "\n",
        "    balance_method = 'undersample'\n",
        "    desired_neg_ratio = 4\n",
        "\n",
        "    print(\"Training with balance_method =\", balance_method)\n",
        "    models, oof = train_lgb_oof(X_tr, y, cat_cols, n_splits=5, seed=42,\n",
        "                                balance_method=balance_method, desired_neg_ratio=desired_neg_ratio)\n",
        "\n",
        "    best_thr, best_f1 = find_best_threshold(y, oof)\n",
        "    print(\"Best threshold on OOF:\", best_thr, \"Best OOF F1:\", best_f1)\n",
        "\n",
        "    print(\"Predicting test set...\")\n",
        "    test_probs = predict_ensemble(models, X_te)\n",
        "    test_pred = (test_probs >= best_thr).astype(int)\n",
        "\n",
        "    if id_col is None or id_col not in X_test.columns:\n",
        "        sub_ids = np.arange(len(test_pred))\n",
        "    else:\n",
        "        sub_ids = X_test[id_col].astype(int).values\n",
        "\n",
        "    submission = pd.DataFrame({\"id\": sub_ids, \"flag\": test_pred})\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"Saved submission.csv, shape:\", submission.shape)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s01f97RHAqF1",
      "metadata": {
        "id": "s01f97RHAqF1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}